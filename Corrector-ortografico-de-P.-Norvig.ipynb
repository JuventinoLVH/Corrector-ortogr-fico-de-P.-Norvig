{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corrector-ortografico-de-P.-Norvig\n",
    "--- \n",
    "\n",
    "\n",
    "---\n",
    "### Tarea\n",
    "- 1) Adapta la función edits1, edits2 para sin considerar la opción de \"transpose\" **(HECHO)**\n",
    "- 2) Programa una tercera función edits3 **(HECHO)**\n",
    "- 3) Justifica porqué las funciones edits1, edits2 nos regresan efectivamente las palabras a \"distancia\" 1 y 2 respectivamente de una palabra dada **(PENDIENTE : Juve)**\n",
    "- 4) Adapta todas las funciones edits para el caso del alfabeto en español **(HECHO)**\n",
    "- 5) Prueba tu corrector con tu propio big.txt (no olvides poner la referencia) **(PENDIENTE : Juan )**\n",
    "- 6) Describe con tus palabras el significado de P(w|c) y P(c|w) ¿porqué es razonable considerar a P(w|c) como el error del modelo **(HECHO : Malcom )**\n",
    "- 7) A qué se refiere Norvig en el punto 4 por \"data on spelling errors\" ¿qué tiene qué ver eso con el error del modelo? **(PENDIENTE : Malcom )**\n",
    "- 8) Explica el procedimiento de Norvig para evaluar el modelo  **(PENDIENTE : Juan)**\n",
    "- 9) Escribe cuidadosamente tus conclusiones **(PENDIENTE : Alondra )**\n",
    "- 10) Poner la descripcion de los 4 conceptops **(PENDIENTE : ALONDRA)**\n",
    "### Equipo cangrejo      \n",
    "* Montaño Preciado Alondra Karolina\n",
    "* Velasquez Hidalgo Luis Juventino\n",
    "* Navarro Lopez Malcom Hiram\n",
    "* Faz Leal Juan Carlos\n",
    "\n",
    "\n",
    "### Fuentes\n",
    "- Libreta de Jupyter de Norbing: https://norvig.com/spell-correct.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Funciones y utilidades usadas en la implementacion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Selection Mechanism`\n",
    "___\n",
    "El Selection Mechanism se encarga de elegir la mejor opción para corregir una palabra mal escrita. Este mecanismo utiliza \n",
    "diferentes técnicas para comparar las palabras generadas por el algoritmo con la original y determinar la mejor opción correcta, el objetivo\n",
    "del Selection Mechanism es mejorar la precisión del corrector ortográfico al elegir la mejor opción de corrección para cada palabra que este mal escrita. \n",
    "\n",
    "En el mecanismo de seleccion se devuelve el valor maximo de un parametro dado de una secuencia de los mismos en este caso la de una palabra. Dada por P(c| w).\n",
    "\n",
    "- Se usa la funcion max para encontrar la palabra con mayor probabilidad.\n",
    "\n",
    "- Correction(word) devuelve una lista de palabras que se encuentran en el texto(los candidatos para la correccion).\n",
    "\n",
    "- key=P es una funcion que devuelve la probabilidad de cada palabra usando la funcion P.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Candidate Model`\n",
    "___\n",
    "\n",
    "El Candidate Model es una lista de palabras que se generan a partir de la palabra mal escrita. estas palabras son sujerencias que el código ofrece al usuario\n",
    "como posibles correcciones( tal vez quisiste decir...), se utilizan diversas técnicas de edición de texto, como la inserción, eliminación, sustitución\n",
    "de letras, etc. Genera una lista de palabras que están a una distancia específica de la palabra mal escrita, se utiliza el Candidate Model para comparar las\n",
    "palabras sugeridas con el texto original y selecciona la palabra que se ajusta mejor al contexto.\n",
    "\n",
    "**PENDIENTE 3)**\n",
    "- recorre la lista de palabras y verifica si se encuentran en el diccionario, si se encuentra, se agrega al conjunto de palabras conocidas que se devuelve. known(words) WORDS \n",
    "- edits1(word): Es una función que toma una palabra y devuelve un conjunto de palabras que están a una edición de distancia de dada palabra. Las ediciones se incluyen en la parte del código. \n",
    "- edits2(word): Es una función que toma una palabra y devuelve un generador de palabras que están a dos ediciones de distancia de dicha palabra, se usa para calcular las palabras que están a una distancia de edición y luego la aplica a cada palabra para calcular a las que están a dos ediciones de distancia.\n",
    "- edits3(word): Identica a edits2, pero usando 'edit2' en vez de 'edit1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyzñáéíóú'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(1,len(word))]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters if c != R[0]]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes  + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "def edits3(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e3 for e2 in edits2(word) for e3 in edits2(e2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hova', 'hxla', 'holi', 'holú', 'holúa', 'holv', 'hjla', 'húola', 'holá', 'hoxla', 'hoca', 'hpola', 'hzola', 'holfa', 'holña', 'hocla', 'hwla', 'héla', 'hgola', 'hoya', 'hsola', 'hovla', 'hofla', 'hoda', 'holc', 'holma', 'holoa', 'hála', 'hoza', 'holca', 'hsla', 'holí', 'hozla', 'hoha', 'hgla', 'hoña', 'hkla', 'holsa', 'holya', 'holxa', 'hmola', 'holl', 'hona', 'holéa', 'horla', 'hbla', 'hdola', 'hoaa', 'hqla', 'hxola', 'holn', 'holva', 'hoíla', 'hfola', 'hosa', 'holm', 'hoka', 'holp', 'hoja', 'holóa', 'hoála', 'holj', 'hopa', 'holh', 'holna', 'hoúla', 'homla', 'holqa', 'holía', 'híla', 'húla', 'hopla', 'hhola', 'hwola', 'hoóla', 'hrola', 'hoéa', 'hoa', 'htla', 'hoyla', 'hóola', 'hols', 'holea', 'hotla', 'hora', 'holñ', 'holq', 'hóla', 'hohla', 'hold', 'hhla', 'holx', 'hlola', 'houla', 'hokla', 'hoáa', 'hcla', 'holo', 'heola', 'hoala', 'hobla', 'hyola', 'holua', 'hooa', 'holz', 'hvla', 'holb', 'hlla', 'hrla', 'homa', 'holy', 'hmla', 'hnola', 'hoia', 'hoñla', 'holt', 'holta', 'hala', 'htola', 'hkola', 'hela', 'holla', 'hoqa', 'hoxa', 'hjola', 'holu', 'hcola', 'hoea', 'howla', 'hpla', 'hoela', 'holaa', 'holga', 'hula', 'hoéla', 'hoúa', 'holáa', 'hla', 'hodla', 'hyla', 'holha', 'holé', 'hojla', 'hoola', 'hqola', 'holba', 'hnla', 'hñola', 'hosla', 'hñla', 'hoía', 'hila', 'holka', 'hol', 'holja', 'héola', 'huola', 'hzla', 'hvola', 'hdla', 'hoqla', 'hoga', 'hoila', 'holra', 'holk', 'holw', 'holpa', 'houa', 'hole', 'háola', 'hogla', 'hfla', 'hoba', 'holf', 'hofa', 'hiola', 'howa', 'haola', 'holwa', 'hbola', 'holr', 'híola', 'hoóa', 'holda', 'hota', 'honla', 'holza', 'holó', 'holia', 'holg'}\n"
     ]
    }
   ],
   "source": [
    "pal = \"hola\"\n",
    "print(edits1(pal))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Language Model`\n",
    "___\n",
    "El Language Model se utiliza para calcular la probabilidad de que una determinada secuencia de palabras aparezca en un lenguaje específico, esto se\n",
    "practica con grandes cantidades de texto para poder predecir que palabras son más propensas a aparecer juntas en una oración. En este caso se utiliza\n",
    "un modelo de lenguaje utiliza estas probabilidades para sugerir correcciones de palabras que estén mal escritas.\n",
    "\n",
    "En esta parte se estima la probabilidad de una palabra contando el numero de veces que cada palabra aparece en un archivo de texto.\n",
    "La funcion words(text) divide el texto en palabras, luego la variable \"WORDS\" contiene un contador de frecuencia de la palabra y P estima la probabilidaad de cada palabra basando se en el contador.\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('TextoEjemplo.txt',encoding=\"UTF8\").read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Error model`\n",
    "___\n",
    "Error Model es el encargado de calcular la probabilidad de que se haya cometido un error ortográfico en una palabra determinada, y qué tipo de\n",
    "error puede ser, para eso se utiliza información estadística sobre el idioma y los errores mas comunes de su escritura, a partir de esta información se\n", 
    "calculan las probabilidades de que la palabra se haya escrito incorrectamente y que error se pudo cometer. \n",
    "\n",
    "**PENDIENTE 6)**\n",
    "Explicar a que se refiere con mecanismo de seleccion y la funcion \n",
    "(Explicar la funcion como si fuera tarea de Irene, plox ) \n",
    "\n",
    "Todas las palabras conocidas de la distancia de edición 1 son infinitamente más probables que las palabras conocidas de Distancia de edición 2, e infinitamente menos probable que una palabra conocida de Editar distancia 0. Así que podemos hacer que los candidatos (palabra) produzcan la primera lista no vacía de candidatos Por orden de prioridad:\n",
    "\n",
    "1.-La palabra original, si se conoce; de otra manera.\n",
    "\n",
    "2.-La lista de palabras conocidas a una distancia de edición, si hay alguna; de otra manera.\n",
    "\n",
    "3.-La lista de palabras conocidas a distancia de edición a dos distancias, si las hay; de otra manera.\n",
    "\n",
    "4.-La palabra original, aunque no se conoce.\n",
    "\n",
    "No se necesita multiplicar por una P(w| c) factor, porque cada candidato en la prioridad elegida tendrá la misma probabilidad (según el modelo defectuoso).\n",
    "\n",
    "Al final se regresa la palabra si esta en el diccionario, si no se regresan las palabras que se encuentran a una distancia de edicion de 1, si no se regresan las palabras que se encuentran a una distancia de edicion de 2, si no se regresa la palabra que se le paso como parametro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluacion usando ...Queda pendiente el texto a usar...**\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PENDIENTE 5)**\n",
    "\n",
    "Prueba tu corrector con tu propio big.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_tests():\n",
    "    # insert Se refiere a agregar una letra adicional a la palabra\n",
    "    assert correction('proocaron') == 'provocaron'\n",
    "    assert correction('pleya') == 'playa'\n",
    "    assert correction('cenizaass') == 'cenizas'\n",
    "\n",
    "    # replace Se refiere a reemplazar una letra de la palabra por otra letra\n",
    "    assert correction('cervamtes') == 'cervantes'\n",
    "    assert correction('amenazaar') == 'amenazar'\n",
    "    assert correction('vallieeron') == 'valieron'\n",
    "\n",
    "    # delete Se refiere a eliminar una letra de la palabra\n",
    "    assert correction('quijte') == 'quijote'\n",
    "    assert correction('despuesa') == 'después'\n",
    "    assert correction('hacerr') == 'hacer'\n",
    "    assert correction('mejorr') == 'mejor'\n",
    "\n",
    "    # transpose Se refiere a intercambiar dos letras adyacentes de la palabra\n",
    "    assert correction('ceravntes') == 'cervantes'\n",
    "    assert correction('ordenaar') == 'ordenar'\n",
    "\n",
    "    # transpose + delete Se refiere a un error en el que se transponen dos letras adyacentes y luego se elimina otra letra de la palabra\n",
    "    assert correction('cervates') == 'cervantes'\n",
    "\n",
    "    # known\n",
    "    assert known(['don', 'quijote', 'cervantes']) == set(['don', 'quijote', 'cervantes'])\n",
    "    assert known(['casa', 'gato', 'perro']) == set(['casa', 'gato', 'perro'])\n",
    "\n",
    "    # unknown\n",
    "    assert known(['donn', 'quixote', 'cervantess']) == set([])\n",
    "    assert known(['artificial', 'inteligence']) == set([])\n",
    "    assert known(['pandas', 'python']) == set([])\n",
    "\n",
    "    return 'unit_tests pass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit_tests pass\n"
     ]
    }
   ],
   "source": [
    "print(unit_tests())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit_tests pass\n",
      "9% of 271 correct (87% unknown) at 9 words per second \n",
      "9% of 271 correct (87% unknown) at 10 words per second \n"
     ]
    }
   ],
   "source": [
    "def spelltest(tests, verbose=False):\n",
    "    \"Run correction(wrong) on all (right, wrong) pairs; report results.\"\n",
    "    import time\n",
    "    start = time.process_time()\n",
    "    good, unknown = 0, 0\n",
    "    n = len(tests)\n",
    "    for right, wrong in tests:\n",
    "        w = correction(wrong)\n",
    "        good += (w == right)\n",
    "        if w != right:\n",
    "            unknown += (right not in WORDS)\n",
    "            if verbose:\n",
    "                print('correction({}) => {} ({}); expected {} ({})'\n",
    "                      .format(wrong, w, WORDS[w], right, WORDS[right]))\n",
    "    dt = time.process_time() - start\n",
    "    print('{:.0%} of {} correct ({:.0%} unknown) at {:.0f} words per second '\n",
    "          .format(good / n, n, unknown / n, n / dt))\n",
    "    \n",
    "def Testset(lines):\n",
    "    \"Parse 'right: wrong1 wrong2' lines into [('right', 'wrong1'), ('right', 'wrong2')] pairs.\"\n",
    "    return [(right, wrong)\n",
    "            for (right, wrongs) in (line.split(':') for line in lines)\n",
    "            for wrong in wrongs.split()]\n",
    "\n",
    "spelltest(Testset(open('spell-testset1.txt'))) # Development set\n",
    "spelltest(Testset(open('spell-testset2.txt'))) # Final test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PENDIENTE 8)**\n",
    "Explica el procedimiento de Norvig para evaluar el modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "___\n",
    "**PENDIENTE 9)**    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
